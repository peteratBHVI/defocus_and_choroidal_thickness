{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Author: p.wagner@bhvi.org / p.wagner@unsw.edu.au \n",
    "image registration of anterior segment projection from several scans \n",
    "\n",
    "Purpose: \n",
    "use averaged rnfl data [per participant, eye, scan_type] to identify macula positioning \n",
    "\n",
    "use inter participant adjustment for macula positioning to match choroid thickness maps per and post intervention \n",
    "\n",
    "calculate final residual \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from scipy import stats\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\p.wagner\\Documents\\Python Scripts\\oct_data_analyses_helpers')\n",
    "from oct_helpers_lib import OctDataAccess as get_px_meta\n",
    "from oct_helpers_lib import TopconSegmentationData as TSD\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "path_oct = r'E:\\studyIII\\OCT_data'\n",
    "path_logbook = r'C:\\Users\\p.wagner\\Documents\\phd\\C4 study_III\\participants'\n",
    "fn_logbook = 'participant_log_studyIII_V0.2.xlsx' \n",
    "fp_fn_logbook = os.path.join(path_logbook, fn_logbook)\n",
    "thickness_csv = 'DEFAULT_3D_All_Thickness.csv'\n",
    "\n",
    "\n",
    "# check if path_oct is available \n",
    "if not os.path.isdir(path_oct):\n",
    "    print('OCT data path NOT available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnfl0_pos_im(px_id, csv_fn, fp_oct, rnfl_0_idx):\n",
    "    fig_output_fn = (str(px_id) + '_' + fn.split('\\\\')[-1].split('.')[0] + '_rnfl_0_thickness_macula.png')\n",
    "\n",
    "    # scatter plot of positions \n",
    "    plt.scatter(rnfl_0_idx[0], rnfl_0_idx[1], s=1)\n",
    "    plt.scatter(np.mean(rnfl_0_idx[0]), np.mean(rnfl_0_idx[1]), s=20, c='red')\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlim([175, 325])\n",
    "    plt.ylim([50, 200])\n",
    "    plt.title = ('PX_id: ' + str(px_id) + ', Scan set: ' + fn.split('\\\\')[-1].split('.')[0]) \n",
    "\n",
    "    \n",
    "    plt.savefig(os.path.join(fp_oct, 'images\\\\rnfl0', fig_output_fn))\n",
    "    plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_with_referece_to_macula(macula_pos_all, scan_type, layer_id, incl_std_factor=2):\n",
    "    # calculate OD initial scan average with adjustment for macula positioning\n",
    "    \n",
    "    slice_width = 16\n",
    "    nan_counter = []\n",
    "    \n",
    "    eye_id = scan_type.split('_')[2]\n",
    "    scan_set = scan_type.split('_')[1]\n",
    "    macula_pos_set = macula_pos_all.loc[(macula_pos_all.eye_id == eye_id) &\n",
    "                                     (macula_pos_all.scan_type == scan_set), :].reset_index(drop=True)\n",
    "    layer_fn_pre = '_'.join([eye_id, 'initial', layer_id, 'mean_regV02.csv'])\n",
    "    layer_fn_post= '_'.join([eye_id, 'post', layer_id, 'mean_regV02.csv'])\n",
    "    \n",
    "    layer_all = []\n",
    "    for idx, layer_fp in enumerate(macula_pos_set.fp):\n",
    "        pos_adjust_layer = np.empty((256, 512), dtype=float)\n",
    "        pos_adjust_layer[:] = np.nan\n",
    "        \n",
    "        layer_initial = pd.read_csv(os.path.join(layer_fp, layer_fn_pre), index_col=0).values.astype(float) \n",
    "        layer_post = pd.read_csv(os.path.join(layer_fp, layer_fn_post ), index_col=0) .values.astype(float)\n",
    "        layer_all_avg = np.mean(np.array([np.array(layer_post), np.array(layer_initial)]), axis=0)\n",
    "\n",
    "        if scan_set == 'initial':\n",
    "            layer = np.array(layer_initial - layer_all_avg)\n",
    "        if scan_set == 'post':\n",
    "            layer = np.array(layer_post - layer_all_avg )\n",
    "                             \n",
    "        row_pos = int(macula_pos_set.loc[idx, 'row_dev'])\n",
    "        col_pos = int(macula_pos_set.loc[idx, 'col_dev'])\n",
    "\n",
    "        print(idx, ' ', macula_pos_set.loc[idx, 'row_dev'], ' ', macula_pos_set.loc[idx, 'col_dev'])\n",
    "        if (row_pos <= 0) & (col_pos <= 0):\n",
    "            pos_adjust_layer[- row_pos: 256, - col_pos:512] = layer[0:256 + row_pos, 0:512 + col_pos]\n",
    "        #         print ('< <')\n",
    "        elif (row_pos <= 0) & (col_pos >= 0):\n",
    "            pos_adjust_layer[- row_pos: 256, 0:512 - col_pos] = layer[0:256 + row_pos, col_pos:512]\n",
    "        #         print( '< > ')\n",
    "        elif (row_pos >= 0) & (col_pos <= 0):\n",
    "            pos_adjust_layer[0: 256 - row_pos, - col_pos:512] = layer[row_pos:256, 0: 512 + col_pos]\n",
    "        #         print( '> < ')\n",
    "        elif (row_pos >= 0) & (col_pos >= 0):\n",
    "            pos_adjust_layer[0:256 - row_pos, 0:512 - col_pos] = layer[row_pos: 256, col_pos: 512]\n",
    "        #         print( '> > ')\n",
    "        #     else:\n",
    "        #         pos_adjust_rnfl = rnfl\n",
    "        #         print( '= =')\n",
    "\n",
    "        # set filter for invalid data exclusion \n",
    "        mean_c_map = np.nanmean(pos_adjust_layer)\n",
    "        std_c_map = np.nanstd(pos_adjust_layer)\n",
    "        print(mean_c_map, std_c_map)\n",
    "        pos_adjust_layer[pos_adjust_layer > ( incl_std_factor * std_c_map + mean_c_map)] = np.nan\n",
    "        pos_adjust_layer[pos_adjust_layer < (-incl_std_factor * std_c_map + mean_c_map)] = np.nan\n",
    "        \n",
    "        \n",
    "#         for idx, x in enumerate(range(0, 513-slice_width, slice_width)):\n",
    "#             slice_mean = np.nanmean(pos_adjust_layer[:, x : x+slice_width])\n",
    "#             slice_std = np.nanstd(pos_adjust_layer[:, x : x+slice_width])\n",
    "#             pos_adjust_layer[:, x : x+slice_width][np.isnan(pos_adjust_layer[:, x : x+slice_width])] = ((np.random.normal(slice_mean, \n",
    "#                                                                                         slice_std, \n",
    "#                                                                                         (pos_adjust_layer[:, x : x+slice_width]\n",
    "#                                                                           [np.isnan(pos_adjust_layer[:, x : x+slice_width])].size))) \n",
    "#                                                                       )\n",
    "\n",
    "        \n",
    "        layer_all.append(pos_adjust_layer)\n",
    "        # count all pixel with depth data \n",
    "        idxs = np.where(np.isnan(pos_adjust_layer)) \n",
    "        mask = np.zeros(pos_adjust_layer.shape)\n",
    "        mask[idxs[0], idxs[1]] = 1\n",
    "        nan_counter.append(mask)\n",
    "        \n",
    "    layer_all = np.array(layer_all)\n",
    "    nan_counter = np.nansum(np.array(nan_counter), axis=0)\n",
    "    return layer_all, nan_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean_all = np.nanmean(layer_all, axis=0)\n",
    "# std_all = np.nanstd(layer_all, axis=0)\n",
    "# max_all = np.nanmax(layer_all, axis=0)\n",
    "# min_all = np.nanmin(layer_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choroid_initial = np.array(OD_pre_layers)\n",
    "# choroid_post = np.array(OD_post_layers)\n",
    "\n",
    "def appl_stats_on_map(map1, map2):\n",
    "    p_values = np.empty((256, 512), dtype=float) \n",
    "\n",
    "    for row_idx in range(0,255): \n",
    "        for col_idx in range(0,511):\n",
    "            array1 = map1[:, row_idx, col_idx]\n",
    "            array2 = map2[:, row_idx, col_idx]\n",
    "\n",
    "            p_values[row_idx, col_idx] = (stats.wilcoxon(array1, array2)[1])\n",
    "    return p_values\n",
    "\n",
    "def map_pValues(display_data, save_file=False, output_fpn=None):\n",
    "    # creating a accumulative map of dioptric landscape\n",
    "    fig = px.imshow(display_data,\n",
    "                    title=title_name,\n",
    "                    labels=dict(x='Horizontal decentration from fovea in degrees [째]',\n",
    "                                y='Vertical decentration from fovea in degrees [째]',\n",
    "                                color=\"p-Values\",\n",
    "                                ),\n",
    "#                     # pixels to degrees translation\n",
    "                    x=np.array([float(x) * 0.0703 for x in range(0, 512)]) - 18,\n",
    "                    y=-1 * np.array([float(x) * 0.10547 for x in range(0, 256)]) + 13.5,\n",
    "#                         y = 1 * np.array([int(x) for x in range(0, 256)])\n",
    "                    )\n",
    "    fig.update_xaxes(side=\"bottom\")\n",
    "    fig.update_yaxes(autorange=True)\n",
    "\n",
    "    fig.update_coloraxes(\n",
    "                          colorscale=[[0.0, \"rgb(255,  0,  0)\"],\n",
    "                                     [0.05, \"rgb(255,  0,  0)\"],\n",
    "                                     [0.05, \"rgb(125,125,  0)\"],\n",
    "                                     [0.1,  \"rgb(125,125,  0)\"],\n",
    "                                     [0.1,  \"rgb(255,255,255)\"],\n",
    "#                                      [0.2,  \"rgb(200,125,100)\"],\n",
    "#                                      [0.2,  \"rgb(200,200,100)\"],\n",
    "#                                      [0.3,  \"rgb(200,200,100)\"],\n",
    "#                                      [0.3,  \"rgb(200,200,200)\"],\n",
    "#                                      [0.5,  \"rgb(200,200,200)\"],\n",
    "                                     [1.0,  \"rgb(155,155,155)\"]],\n",
    "                        colorbar_title_side='right',\n",
    "                        colorbar_tickfont=dict(size=18, ),\n",
    "                        colorbar_title_font=dict(size=18, ),\n",
    "                        reversescale=False\n",
    "                         )\n",
    "\n",
    "    fig.update_layout(title_font_size=24,\n",
    "                      autosize=True,\n",
    "                      width=1200, height=900,\n",
    "                      margin=dict(l=10, r=10, b=10, t=40),\n",
    "                      )\n",
    "    fig.update_xaxes(title_font=dict(size=22, ), tickfont=dict(size=18), )\n",
    "    fig.update_yaxes(title_font=dict(size=22, ), tickfont=dict(size=18), )\n",
    "\n",
    "    if save_file:\n",
    "        fig.write_image(output_fpn)\n",
    "    else:\n",
    "        fig.show()\n",
    "        \n",
    "def map_significant_data(display_data, save_file=False, output_fpn=None):\n",
    "    # creating a accumulative map of dioptric landscape\n",
    "    fig = px.imshow(display_data,\n",
    "                    title=title_name,\n",
    "                    labels=dict(x='Horizontal decentration from fovea in degrees [째]',\n",
    "                                y='Vertical decentration from fovea in degrees [째]',\n",
    "                                color=\"thickness change in micrometer\",\n",
    "                                ),\n",
    "#                     # pixels to degrees translation\n",
    "                    x=np.array([float(x) * 0.0703 for x in range(0, 512)]) - 18,\n",
    "                    y=-1 * np.array([float(x) * 0.10547 for x in range(0, 256)]) + 13.5,\n",
    "#                         y = 1 * np.array([int(x) for x in range(0, 256)])\n",
    "                    )\n",
    "    fig.update_xaxes(side=\"bottom\")\n",
    "    fig.update_yaxes(autorange=True)\n",
    "\n",
    "    fig.update_coloraxes(cmin=-30,\n",
    "                         cmax= 30,\n",
    "                         colorscale='Portland',\n",
    "\n",
    "#                           colorscale=[[0.0, \"rgb(255,  0,  0)\"],\n",
    "#                                      [0.05, \"rgb(255,  0,  0)\"],\n",
    "#                                      [0.05, \"rgb(125,125,  0)\"],\n",
    "#                                      [0.1,  \"rgb(125,125,  0)\"],\n",
    "#                                      [0.1,  \"rgb(255,255,255)\"],\n",
    "# #                                      [0.2,  \"rgb(200,125,100)\"],\n",
    "# #                                      [0.2,  \"rgb(200,200,100)\"],\n",
    "# #                                      [0.3,  \"rgb(200,200,100)\"],\n",
    "# #                                      [0.3,  \"rgb(200,200,200)\"],\n",
    "# #                                      [0.5,  \"rgb(200,200,200)\"],\n",
    "#                                      [1.0,  \"rgb(155,155,155)\"]],\n",
    "                        colorbar_title_side='right',\n",
    "                        colorbar_tickfont=dict(size=18, ),\n",
    "                        colorbar_title_font=dict(size=18, ),\n",
    "                        reversescale=False,\n",
    "                         )\n",
    "\n",
    "    fig.update_layout(title_font_size=24,\n",
    "                      autosize=True,\n",
    "                      width=1200, height=900,\n",
    "                      margin=dict(l=10, r=10, b=10, t=40),\n",
    "                      )\n",
    "    fig.update_xaxes(title_font=dict(size=22, ), tickfont=dict(size=18), )\n",
    "    fig.update_yaxes(title_font=dict(size=22, ), tickfont=dict(size=18), )\n",
    "\n",
    "    if save_file:\n",
    "        fig.write_image(output_fpn)\n",
    "    else:\n",
    "        fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 26, ] # all px\n",
    "# px_ids = [1,    3, 4, 5, 6,       9, 10, 11,     13, 14, 15, 16, 17, 18, 20, 23, ] # bad scan out  \n",
    "\n",
    "# px_ids =[16, ]\n",
    "\n",
    "scan_types_all = ['OCT_initial_OD', 'OCT_post_OD', 'OCT_initial_OS', 'OCT_post_OS']\n",
    "    \n",
    "\n",
    "column_names = ['px_id', 'eye_id', 'scan_type', 'fp', 'macula_row_pos', 'macula_col_pos']    \n",
    "macula_pos_all = pd.DataFrame(columns=column_names)\n",
    "for px_id in px_ids:\n",
    "    px_meta_data = get_px_meta(fp_fn_logbook, [px_id,], scan_types_all, path_oct)\n",
    "    for fn in glob.glob(os.path.join(px_meta_data.subject_rec_fp[0] ,'*rnfl_mean_reg.csv')):\n",
    "        # get scan type \n",
    "        eye_id = fn.split('\\\\')[-1].split('.')[0].split('_')[0]\n",
    "        scan_type = fn.split('\\\\')[-1].split('.')[0].split('_')[1]    \n",
    "        # read fn \n",
    "        rnfl_data = pd.read_csv(fn, index_col=0)\n",
    "        # look in interval [50:200, 175:325] for 0 pos or smaler xx for macula position \n",
    "        rnfl_macula = rnfl_data.iloc[50:200, 175:325].values\n",
    "        # calculate centre position \n",
    "        # horizontal positioning == column space counted from the top left\n",
    "        row_pos = np.mean(np.where(rnfl_macula < 1)[0] + 50) \n",
    "        # vertical positionng == row space \n",
    "        col_pos = np.mean(np.where(rnfl_macula < 1)[1] + 175)\n",
    "\n",
    "\n",
    "        rnfl_macula_idxs = (np.where(rnfl_macula < 1)[1] + 175),  (256 + -(np.where(rnfl_macula < 1)[0] + 50))\n",
    "\n",
    "        macula_pos_all = macula_pos_all.append(pd.DataFrame({'px_id':px_id,\n",
    "                                     'eye_id' : eye_id,  \n",
    "                                     'scan_type': scan_type,\n",
    "                                     'fp': '\\\\'.join(fn.split('\\\\')[:-1]),\n",
    "                                     'macula_row_pos': [row_pos], \n",
    "                                     'macula_col_pos': [col_pos]\n",
    "                                                              }))\n",
    "        \n",
    "#         # create scatter plot and save to file for quality check\n",
    "#         create_rnfl0_pos_im(px_id, fn, path_oct, rnfl_macula_idxs)\n",
    "        \n",
    "#         print(fn)\n",
    "# record center position for all averged sets of scans                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating residual of center positions for each eye across pre and post intervention \n",
    "macula_pos_all.loc[macula_pos_all.eye_id =='OD', 'col_dev' ] = np.round(macula_pos_all.loc[macula_pos_all.eye_id =='OD',  'macula_col_pos']-\n",
    "                                                                np.mean(macula_pos_all.loc[macula_pos_all.eye_id =='OD',  'macula_col_pos']), 0)\n",
    "\n",
    "macula_pos_all.loc[macula_pos_all.eye_id =='OD', 'row_dev' ] = np.round(macula_pos_all.loc[macula_pos_all.eye_id =='OD',  'macula_row_pos']-\n",
    "                                                                np.mean(macula_pos_all.loc[macula_pos_all.eye_id =='OD',  'macula_row_pos']), 0)                                                                                   \n",
    "\n",
    "macula_pos_all.loc[macula_pos_all.eye_id =='OS', 'col_dev' ] = np.round(macula_pos_all.loc[macula_pos_all.eye_id =='OS',  'macula_col_pos']-\n",
    "                                                                np.mean(macula_pos_all.loc[macula_pos_all.eye_id =='OS',  'macula_col_pos']), 0)\n",
    "\n",
    "macula_pos_all.loc[macula_pos_all.eye_id =='OS', 'row_dev' ] = np.round(macula_pos_all.loc[macula_pos_all.eye_id =='OS',  'macula_row_pos']-\n",
    "                                                                np.mean(macula_pos_all.loc[macula_pos_all.eye_id =='OS',  'macula_row_pos']), 0) \n",
    "                                                                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # apply residual to average across averaged rnfl maps \n",
    "std_incl_factor = 2\n",
    "layer_id = 'choroid'\n",
    "scan_type = 'OCT_initial_OD'\n",
    "\n",
    "OD_pre_layers, OD_pre_nans = average_with_referece_to_macula(macula_pos_all, scan_type, layer_id, std_incl_factor)\n",
    "\n",
    "scan_type = 'OCT_post_OD'\n",
    "\n",
    "OD_post_layers, OD_post_nans = average_with_referece_to_macula(macula_pos_all, scan_type, layer_id, std_incl_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# output_fp = r'E:\\studyIII\\OCT_data\\images\\residuals'\n",
    "\n",
    "# OD_residual = OD_post_layers - OD_pre_layers\n",
    "# # OS_residual = OS_pre_layers - OS_post_layers\n",
    "\n",
    "# for idx, px_id in enumerate(px_ids):\n",
    "#     output_fn = str(px_id) + '_OD_choroid_thickness_residual_pre_post.png'\n",
    "#     output_fpn = os.path.join(output_fp, output_fn)\n",
    "#     display_data = OD_residual[idx, :,:]\n",
    "    \n",
    "#     title_name = ('Choroid thickness residual OD, px_id: ' + str(px_id) +\n",
    "#                   ', avg: ' + str(np.round(np.nanmean(display_data), 2)) +\n",
    "#                   ', std: ' + str(np.round(np.nanstd(display_data), 2))  +\n",
    "#                   ', max: ' + str(np.round(np.nanmax(display_data), 2)) + \n",
    "#                   ', min: ' + str(np.round(np.nanmin(display_data), 2))        \n",
    "#                  ) \n",
    "#     map_significant_data(display_data, save_file=True, output_fpn=output_fpn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data to a csv file \n",
    "# output_fp = r'E:\\studyIII\\OCT_final_data\\95perc'\n",
    "# for idx, px_id in enumerate(px_ids):\n",
    "#     # pre intervention\n",
    "#     output_fn = '_'.join(['choroid_thickness_map_95perc_initial', \n",
    "#                           str(px_id), \n",
    "#                           scan_type.split('_')[-1],\n",
    "#                          '.csv'])\n",
    "#     output_layer = pd.DataFrame (OD_pre_layers[idx, :,:])\n",
    "#     output_layer.to_csv(os.path.join(output_fp, output_fn), index=True)\n",
    "#     # post intervention\n",
    "#     output_fn = '_'.join(['choroid_thickness_map_95perc_post', \n",
    "#                           str(px_id), \n",
    "#                           scan_type.split('_')[-1],\n",
    "#                          '.csv'])\n",
    "#     output_layer = pd.DataFrame (OD_post_layers[idx, :,:])\n",
    "#     output_layer.to_csv(os.path.join(output_fp, output_fn), index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create box plot right left and centre in quarters \n",
    "\n",
    "max_exclusion = 5\n",
    "mask = np.ones((256, 512))\n",
    "idxs = np.where(OD_pre_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(OD_post_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(mask == 0)\n",
    "\n",
    "OD_initial_mean = np.nanmean(OD_pre_layers, axis=0)\n",
    "OD_post_mean = np.nanmean(OD_post_layers, axis=0)\n",
    "\n",
    "# dispaly_data\n",
    "display_data = (OD_post_mean - OD_initial_mean) \n",
    "display_data[idxs] = np.nan\n",
    "\n",
    "left = display_data[0:256, 0:128][~np.isnan(display_data[0:256, 0:128])]\n",
    "\n",
    "centre = display_data[50: 200, 192:320][~np.isnan(display_data[50: 200, 192:320])]\n",
    "\n",
    "right = display_data[0:256, 384:512][~np.isnan(display_data[0:256, 384:512])]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=80)\n",
    "data = [left, centre, right]\n",
    "fig7, ax7 = plt.subplots(figsize=(12, 8), dpi=80)\n",
    "ax7.set_title('Effects of optical defocus on central (foveal) and peripheral retina')\n",
    "ax7.boxplot(data)\n",
    "plt.xticks([1, 2, 3], ['myopic defocus peripheral left', 'centre fovea area', 'hyperopic defocus peripheral right'])\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumarize data from areas and record in table, to csv\n",
    "\n",
    "scan_types_all = ['OCT_initial_OD', 'OCT_post_OD', 'OCT_initial_OS', 'OCT_post_OS']\n",
    "column_names = ['px_id', 'scan_type', 'overall_mean', 'overall_std', \n",
    "                'lhs_area_mean', 'lhs_area_std',\n",
    "                'centre_area_mean', 'centre_area_std',\n",
    "                'rhs_area_mean', 'rhs_area_std',\n",
    "               ]\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "for idx, px_id in enumerate(px_ids):\n",
    "    for scan_type, data in zip(scan_types_all, [OD_pre_layers, OD_post_layers, OS_pre_layers, OS_post_layers]):\n",
    "        df_new = pd.DataFrame(columns=column_names)\n",
    "        df_new.loc[0,'px_id'] = px_id\n",
    "        df_new.loc[0,'scan_type'] = scan_type\n",
    "        df_new.loc[0,'overall_mean'] = np.nanmean(data[idx, :,:])\n",
    "        df_new.loc[0,'overall_std'] =  np.nanstd( data[idx, :,:])                                         \n",
    "\n",
    "        left = data[idx, 0:256, 0:128][~np.isnan(data[idx, 0:256, 0:128])]\n",
    "        df_new.loc[0,'lhs_area_mean'] = np.nanmean(left)\n",
    "        df_new.loc[0,'lhs_area_std'] =  np.nanstd( left)                                         \n",
    "\n",
    "        centre = data[idx, 50: 200, 192:320][~np.isnan(data[idx, 50: 200, 192:320])]\n",
    "        df_new.loc[0,'centre_area_mean'] = np.nanmean(centre)\n",
    "        df_new.loc[0,'centre_area_std'] =  np.nanstd(centre)  \n",
    "        \n",
    "        right = data[idx, 0:256, 384:512][~np.isnan(data[idx, 0:256, 384:512])]\n",
    "        df_new.loc[0,'rhs_area_mean'] = np.nanmean(right)\n",
    "        df_new.loc[0,'rhs_area_std'] =  np.nanstd(right)  \n",
    "\n",
    "        df = df.append(df_new)\n",
    "df.to_csv('mean_residuals_in_different_areas_' + str(std_incl_factor) + 'std_incl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs_data = df.loc[df.scan_type == 'OCT_post_OD', 'lhs_area_mean'] - df.loc[df.scan_type == 'OCT_initial_OD', 'lhs_area_mean']\n",
    "centre_data = df.loc[df.scan_type == 'OCT_post_OD', 'centre_area_mean'] - df.loc[df.scan_type == 'OCT_initial_OD', 'centre_area_mean']\n",
    "rhs_data = df.loc[df.scan_type == 'OCT_post_OD', 'rhs_area_mean'] - df.loc[df.scan_type == 'OCT_initial_OD', 'rhs_area_mean']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=80)\n",
    "data = [lhs_data, centre_data, rhs_data]\n",
    "fig7, ax7 = plt.subplots(figsize=(12, 8), dpi=80)\n",
    "ax7.set_title('Effects of optical defocus on central (foveal) and peripheral retina')\n",
    "ax7.boxplot(data)\n",
    "plt.xticks([1, 2, 3], ['myopic defocus peripheral left', 'centre fovea area', 'hyperopic defocus peripheral right'])\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OD_pre_layers, OD_post_layers, OS_pre_layers, OS_post_layers\n",
    "OD_residual = OD_post_layers - OD_pre_layers\n",
    "OS_residual = OS_post_layers - OS_pre_layers\n",
    "\n",
    "OD_residual_mean = []\n",
    "OD_residual_std =[]\n",
    "OD_left_area_means = []\n",
    "OD_centre_area_means = []\n",
    "OD_right_area_means = []\n",
    "\n",
    "OS_residual_mean = []\n",
    "OS_residual_std =[]\n",
    "OS_left_area_means = []\n",
    "OS_centre_area_means = []\n",
    "OS_right_area_means = []\n",
    "\n",
    "for idx, px_id in enumerate(px_ids):\n",
    "    \n",
    "    OD_residual_mean.append(np.nanmean(OD_residual[idx, :, :]))\n",
    "    OD_residual_std.append(np.nanmean(OD_residual[idx, :, :]))  \n",
    "    OD_left_area_means.append(np.nanmean(OD_residual[idx, 0:256, 0:128]))\n",
    "    OD_centre_area_means.append(np.nanmean(OD_residual[idx, 50: 200, 192:320]))\n",
    "    OD_right_area_means.append(np.nanmean(OD_residual[idx, 0:256, 384:512]))\n",
    "    \n",
    "    OS_residual_mean.append(np.nanmean(OS_residual[idx, :, :]))\n",
    "    OS_residual_std.append(np.nanmean(OS_residual[idx, :, :]))     \n",
    "    OS_left_area_means.append(np.nanmean(OS_residual[idx, 0:256, 0:128]))\n",
    "    OS_centre_area_means.append(np.nanmean(OS_residual[idx, 50: 200, 192:320]))\n",
    "    OS_right_area_means.append(np.nanmean(OS_residual[idx, 0:256, 384:512]))\n",
    "    \n",
    "plt.figure(figsize=(12, 8), dpi=80)\n",
    "data = [OD_left_area_means, OD_centre_area_means, OD_right_area_means,\n",
    "       OS_left_area_means, OS_centre_area_means, OS_right_area_means,\n",
    "       ]\n",
    "fig7, ax7 = plt.subplots(figsize=(12, 8), dpi=80)\n",
    "ax7.set_title('Effects of optical defocus on central (foveal) and peripheral retina')\n",
    "ax7.boxplot(data)\n",
    "plt.xticks([1, 2, 3], ['myopic defocus peripheral left', 'centre fovea area', 'hyperopic defocus peripheral right'])\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, px_id in enumerate(px_ids):\n",
    "    print(px_id, 'OD residual mean: ', np.round(np.nanmean(OD_residual[idx, :,:]), 2), \n",
    "         'std: ', np.round(np.nanstd(OD_residual[idx, :,:]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OD_pre_nans[OD_pre_nans>10] = 10\n",
    "\n",
    "# display_data = OD_pre_nans\n",
    "# display_data[display_data>10] = 10\n",
    "fig = go.Figure(data=[go.Surface(z=-display_data)])\n",
    "\n",
    "\n",
    "fig.update_layout(scene_camera_eye=dict(y=-4, x=0.01, z=-12),\n",
    "                  scene_aspectmode='manual', \n",
    "                  scene_aspectratio=dict(x=12, y=9, z=10),\n",
    "                  scene = dict(xaxis = dict(nticks=10, range=[0,512],),\n",
    "                               yaxis = dict(nticks=10, range=[0,256],),\n",
    "                               zaxis = dict(nticks=10, range=[-30,30],),),)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_exclusion = 10\n",
    "mask = np.ones((256, 512))\n",
    "idxs = np.where(OD_pre_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(OD_post_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(mask == 0)\n",
    "\n",
    "OD_initial_mean = np.nanmean(OD_pre_layers, axis=0)\n",
    "OD_post_mean = np.nanmean(OD_post_layers, axis=0)\n",
    "\n",
    "OD_initial_std = np.nanstd(OD_pre_layers, axis=0)\n",
    "OD_post_std = np.nanstd(OD_post_layers, axis=0)\n",
    "\n",
    "display_data = (OD_post_mean - OD_initial_mean) \n",
    "display_data[idxs] = np.nan\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=np.array(display_data.T))])\n",
    "\n",
    "title_name = ('Choroid thickness, '+ scan_type.split('_')[-1] +', STD post intervention' +\n",
    "              ', avg: ' + str(np.round(np.nanmean(display_data), 2)) +\n",
    "              ', std: ' + str(np.round(np.nanstd(display_data), 2))  +\n",
    "              ', max: ' + str(np.round(np.nanmax(display_data), 2)) + \n",
    "              ', min: ' + str(np.round(np.nanmin(display_data), 2)) \n",
    "             ) \n",
    "\n",
    "fig.update_layout(title=title_name, title_font_size=22, autosize=False,\n",
    "                  width=1200, height=900,\n",
    "                  margin=dict(l=50, r=50, b=50, t=50), \n",
    "                  )\n",
    "\n",
    "fig.update_layout(scene_camera_eye=dict(x=4, y=-0.01, z=22),\n",
    "                  scene_aspectmode='manual', \n",
    "                  scene_aspectratio=dict(x=9, y=12, z=10),\n",
    "                  scene = dict(xaxis = dict(nticks=10, range=[0,256],),\n",
    "                               yaxis = dict(nticks=10, range=[0,512],),\n",
    "                               zaxis = dict(nticks=10, range=[-30,30],),),)\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis_title='vertical pixel position',\n",
    "                    yaxis_title='thickness map, horizontal pixel position',\n",
    "                    zaxis_title='thickness in micrometer'),\n",
    "                 )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean: ', np.nanmean(display_data), ' std: ', np.nanstd(display_data))\n",
    "fig_hist =plt.hist(display_data.flatten(), 100)\n",
    "\n",
    "map_significant_data(display_data, save_file=False, output_fpn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating p-Values with Wilcoxon stats test\n",
    "p_values = appl_stats_on_map(OD_post_layers, OD_pre_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((256, 512))\n",
    "idxs = np.where(OD_pre_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(OD_post_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(mask == 0)\n",
    "\n",
    "\n",
    "display_data = p_values\n",
    "display_data[idxs[0], idxs[1]] = np.nan\n",
    "\n",
    "im_output_fn = 'OD_all_wilcoxon_choroid_thickness_delta_reg_mm_outlierremoval.png'\n",
    "\n",
    "title_name = ('Choroid thickness mean residual stats, OD, all px, Wilcoxon signed-rank test') \n",
    "map_pValues(p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data = (OD_post_mean - OD_initial_mean) \n",
    "\n",
    "idxs = np.where(OD_pre_nans>=max_exclusion)\n",
    "display_data[idxs] = np.nan\n",
    "idxs = np.where(OD_post_nans>=max_exclusion)\n",
    "display_data[idxs] = np.nan\n",
    "\n",
    "idxs = np.where(p_values>0.05)\n",
    "display_data[idxs] = np.nan\n",
    "title_name = ('Choroid thickness areas of significant change, OD, stats Wilcoxon signed-rank test') \n",
    "map_significant_data(display_data, save_file=False, output_fpn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data = OD_pre_nans\n",
    "title_name = ('count of valid data form participants per pixel position') \n",
    "map_significant_data(display_data, save_file=False, output_fpn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply residual to average across averaged rnfl maps \n",
    "std_incl_factor = 2\n",
    "layer_id = 'choroid'\n",
    "scan_type = 'OCT_initial_OS'\n",
    "\n",
    "OS_pre_layers, OS_pre_nans = average_with_referece_to_macula(macula_pos_all, scan_type, layer_id, std_incl_factor)\n",
    "\n",
    "layer_id = 'choroid'\n",
    "scan_type = 'OCT_post_OS'\n",
    "\n",
    "OS_post_layers, OS_post_nans = average_with_referece_to_macula(macula_pos_all, scan_type, layer_id, std_incl_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_fp = r'E:\\studyIII\\OCT_data\\images\\residuals'\n",
    "\n",
    "# # OD_residual = OD_pre_layers - OD_post_layers\n",
    "# OS_residual = OS_post_layers - OS_pre_layers\n",
    "\n",
    "# for idx, px_id in enumerate(px_ids):\n",
    "#     output_fn = str(px_id) + '_OS_choroid_thickness_residual_pre_post.png'\n",
    "#     output_fpn = os.path.join(output_fp, output_fn)\n",
    "#     display_data = OS_residual[idx, :,:]\n",
    "    \n",
    "#     title_name = ('Choroid thickness residual OS, px_id: ' + str(px_id) +\n",
    "#                   ', avg: ' + str(np.round(np.nanmean(display_data), 2)) +\n",
    "#                   ', std: ' + str(np.round(np.nanstd(display_data), 2))  +\n",
    "#                   ', max: ' + str(np.round(np.nanmax(display_data), 2)) + \n",
    "#                   ', min: ' + str(np.round(np.nanmin(display_data), 2))        \n",
    "#                  ) \n",
    "#     map_significant_data(display_data, save_file=True, output_fpn=output_fpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data to a csv file \n",
    "# output_fp = r'E:\\studyIII\\OCT_final_data\\95perc'\n",
    "# for idx, px_id in enumerate(px_ids):\n",
    "#     # pre intervention\n",
    "#     output_fn = '_'.join(['choroid_thickness_map_95perc_initial', \n",
    "#                           str(px_id), \n",
    "#                           scan_type.split('_')[-1],\n",
    "#                          '.csv'])\n",
    "#     output_layer = pd.DataFrame (OS_pre_layers[idx, :,:])\n",
    "#     output_layer.to_csv(os.path.join(output_fp, output_fn), index=True)\n",
    "#     # post intervention\n",
    "#     output_fn = '_'.join(['choroid_thickness_map_95perc_post', \n",
    "#                           str(px_id), \n",
    "#                           scan_type.split('_')[-1],\n",
    "#                          '.csv'])\n",
    "#     output_layer = pd.DataFrame (OS_post_layers[idx, :,:])\n",
    "#     output_layer.to_csv(os.path.join(output_fp, output_fn), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create box plot right left and centre in quarters \n",
    "#  create box plot right left and centre in quarters \n",
    "\n",
    "max_exclusion = 5\n",
    "mask = np.ones((256, 512))\n",
    "idxs = np.where(OS_pre_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(OS_post_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(mask == 0)\n",
    "\n",
    "OS_initial_mean = np.nanmean(OS_pre_layers, axis=0)\n",
    "OS_post_mean = np.nanmean(OS_post_layers, axis=0)\n",
    "\n",
    "# dispaly_data\n",
    "display_data = (OS_post_mean - OS_initial_mean) \n",
    "display_data[idxs] = np.nan\n",
    "\n",
    "left = display_data[0:256, 0:128][~np.isnan(display_data[0:256, 0:128])]\n",
    "\n",
    "centre = display_data[50: 200, 192:320][~np.isnan(display_data[50: 200, 192:320])]\n",
    "\n",
    "right = display_data[0:256, 384:512][~np.isnan(display_data[0:256, 384:512])]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=80)\n",
    "data = [left, centre, right]\n",
    "fig7, ax7 = plt.subplots(figsize=(12, 8), dpi=80)\n",
    "ax7.set_title('Effects of optical defocus on central (foveal) and peripheral retina')\n",
    "ax7.boxplot(data)\n",
    "plt.xticks([1, 2, 3], ['myopic defocus peripheral left', 'centre fovea area', 'hyperopic defocus peripheral right'])\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OD_pre_nans[OD_pre_nans>10] = 10\n",
    "\n",
    "display_data = OS_pre_nans\n",
    "display_data[display_data>10] = 10\n",
    "fig = go.Figure(data=[go.Surface(z=-display_data)])\n",
    "\n",
    "\n",
    "fig.update_layout(scene_camera_eye=dict(y=-4, x=0.01, z=-12),\n",
    "                  scene_aspectmode='manual', \n",
    "                  scene_aspectratio=dict(x=12, y=9, z=10),\n",
    "                  scene = dict(xaxis = dict(nticks=10, range=[0,512],),\n",
    "                               yaxis = dict(nticks=10, range=[0,256],),\n",
    "                               zaxis = dict(nticks=10, range=[-30,30],),),)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_exclusion = 10\n",
    "mask = np.ones((256, 512))\n",
    "idxs = np.where(OS_pre_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(OS_post_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(mask == 0)\n",
    "\n",
    "OS_initial_mean = np.nanmean(OS_pre_layers, axis=0)\n",
    "OS_post_mean = np.nanmean(OS_post_layers, axis=0)\n",
    "\n",
    "OS_initial_std = np.nanstd(OS_pre_layers, axis=0)\n",
    "OS_post_std = np.nanstd(OS_post_layers, axis=0)\n",
    "\n",
    "display_data = (OS_post_mean - OS_initial_mean) \n",
    "display_data[idxs] = np.nan\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=np.array(display_data.T))],)\n",
    "\n",
    "title_name = ('Choroid thickness, '+ scan_type.split('_')[-1] +', STD post intervention' +\n",
    "              ', avg: ' + str(np.round(np.nanmean(display_data), 2)) +\n",
    "              ', std: ' + str(np.round(np.nanstd(display_data), 2))  +\n",
    "              ', max: ' + str(np.round(np.nanmax(display_data), 2)) + \n",
    "              ', min: ' + str(np.round(np.nanmin(display_data), 2)) \n",
    "             ) \n",
    "\n",
    "fig.update_layout(title=title_name, title_font_size=22, autosize=False,\n",
    "                  width=1200, height=900,\n",
    "                  margin=dict(l=50, r=50, b=50, t=50), \n",
    "                  \n",
    "                  )\n",
    "# fig.ColorBar(cmid=0)\n",
    "fig.update_layout(coloraxis = dict(colorscale='balance', colorbar_len=0.7),)\n",
    "# #                     colorbar_title_side='right',\n",
    "# #                     colorscale='RdYlGn',\n",
    "# #                     colorbar_tickfont=dict(size=18, ),\n",
    "# #                     colorbar_title_font=dict(size=18, ),\n",
    "# #                     reversescale=True\n",
    "#                      )\n",
    "\n",
    "fig.update_layout(scene_camera_eye=dict(x=4, y=-0.01, z=22),\n",
    "                  scene_aspectmode='manual', \n",
    "                  scene_aspectratio=dict(x=9, y=12, z=10),\n",
    "                  scene = dict(xaxis = dict(nticks=10, range=[0,256],),\n",
    "                               yaxis = dict(nticks=10, range=[0,512],),\n",
    "                               zaxis = dict(nticks=10, range=[-30,30],),),)\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis_title='vertical pixel position',\n",
    "                    yaxis_title='thickness map, horizontal pixel position',\n",
    "                    zaxis_title='thickness in micrometer'),\n",
    "                 )\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean: ', np.nanmean(display_data), ' std: ', np.nanstd(display_data))\n",
    "fig_hist =plt.hist(display_data.flatten(), 100)\n",
    "\n",
    "map_significant_data(display_data, save_file=False, output_fpn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating p-Values with Wilcoxon stats test\n",
    "p_values = appl_stats_on_map(OS_pre_layers, OS_post_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((256, 512))\n",
    "idxs = np.where(OS_pre_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(OS_post_nans>=max_exclusion)\n",
    "mask[idxs[0], idxs[1]] = 0\n",
    "idxs = np.where(mask == 0)\n",
    "\n",
    "\n",
    "display_data = p_values\n",
    "display_data[idxs[0], idxs[1]] = np.nan\n",
    "\n",
    "im_output_fn = 'OS_all_wilcoxon_choroid_thickness_delta_reg_mm_outlierremoval.png'\n",
    "\n",
    "title_name = ('Choroid thickness mean residual stats, OS, all px, Wilcoxon signed-rank test') \n",
    "map_pValues(p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_data = (OS_post_mean - OS_initial_mean) \n",
    "\n",
    "idxs = np.where(OS_pre_nans>=max_exclusion)\n",
    "display_data[idxs] = np.nan\n",
    "idxs = np.where(OS_post_nans>=max_exclusion)\n",
    "display_data[idxs] = np.nan\n",
    "\n",
    "idxs = np.where(p_values>0.05)\n",
    "display_data[idxs] = np.nan\n",
    "title_name = ('Choroid thickness areas of significant change, OS, stats Wilcoxon signed-rank test') \n",
    "map_significant_data(display_data, save_file=False, output_fpn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
